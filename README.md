# Getting Started with Snowflake Openflow Kafka Connector

Companion repository for the [Snowflake Openflow Kafka Connector Quickstart](https://quickstarts.snowflake.com/guide/getting_started_with_openflow_kafka_connector/index.html).

## Overview

Build a real-time streaming pipeline from Apache Kafka to Snowflake using Openflow. Stream application logs from Kafka to Snowflake with automatic schema detection, schema evolution, and perform powerful SQL analytics including semantic search with Cortex Search.

**üìñ [Follow the Complete Quickstart Guide](https://quickstarts.snowflake.com/guide/getting_started_with_openflow_kafka_connector/index.html)**

## Repository Contents

```
.
‚îú‚îÄ‚îÄ README.md                      # This file
‚îú‚îÄ‚îÄ RPK_CLI_README.md              # Detailed RPK CLI setup guide
‚îú‚îÄ‚îÄ Taskfile.yml                   # Task runner for common operations
‚îú‚îÄ‚îÄ LICENSE.txt                    # Apache 2.0 license
‚îú‚îÄ‚îÄ pyproject.toml                 # Python project dependencies
‚îú‚îÄ‚îÄ .env.template                  # Environment variable template
‚îú‚îÄ‚îÄ sql/
‚îÇ   ‚îú‚îÄ‚îÄ 1.snowflake_setup.sql     # Snowflake environment setup
‚îÇ   ‚îú‚îÄ‚îÄ 2.verify_ingestion.sql    # Data ingestion verification
‚îÇ   ‚îú‚îÄ‚îÄ 2a.verify_base_schema.sql # Verify base schema ingestion
‚îÇ   ‚îú‚îÄ‚îÄ 2b.verify_schema_evolution.sql # Verify schema evolution
‚îÇ   ‚îú‚îÄ‚îÄ 3.analytics_queries.sql   # Example analytics queries
‚îÇ   ‚îú‚îÄ‚îÄ 4.cortex_search.sql       # Semantic search with Cortex Search
‚îÇ   ‚îî‚îÄ‚îÄ 5.cleanup.sql             # Cleanup script
‚îî‚îÄ‚îÄ sample-data/
    ‚îú‚îÄ‚îÄ sample_logs.json           # 50 base schema sample records
    ‚îú‚îÄ‚îÄ sample_logs_evolved.json   # 80 evolved schema sample records
    ‚îî‚îÄ‚îÄ generate_logs.py           # Python log generator script
```

## Quick Start

### 1. Clone and Setup

```bash
git clone https://github.com/Snowflake-Labs/sfguide-getting-started-openflow-kafka-connector.git
cd sfguide-getting-started-openflow-kafka-connector
export QUICK_START_REPO=$PWD
```

### 2. Install Task Runner (Optional)

```bash
# macOS
brew install go-task

# Linux
sh -c "$(curl --location https://taskfile.dev/install.sh)" -- -d -b ~/.local/bin

# See all available tasks
task list
```

### 3. Follow the Quickstart Guide

**üëâ [Complete Step-by-Step Instructions](https://quickstarts.snowflake.com/guide/getting_started_with_openflow_kafka_connector/index.html)**

The quickstart guide walks you through:

- Setting up Kafka and rpk CLI
- Configuring Snowflake (database, network rules, External Access Integration)
- Deploying Openflow SPCS runtime
- Configuring the Kafka connector with automatic schema evolution
- Generating and streaming logs
- Running analytics and Cortex Search queries

## Common Tasks

### Generate Sample Files (No Kafka Required)

```bash
task generate-samples   # Generate both base and evolved sample files
task generate-base      # Generate 50 base schema records
task generate-evolved   # Generate 80 evolved schema records
```

### Test Kafka Connection

```bash
# Setup environment
cp .env.template .env   # Edit with your Kafka credentials
task test-kafka         # Verify connection
```

### Produce Logs to Kafka

```bash
# Using Python generator
task produce-base       # Produce 50 base schema logs
task produce-evolved    # Produce 80 evolved schema logs

# Using rpk (faster)
task rpk-produce-base
task rpk-produce-evolved

# Complete demo workflow
task demo-full          # Run Phase 1 + Phase 2
```

### Kafka Topic Management

```bash
task kafka-create-topic      # Create application-logs topic
task kafka-topics            # List all topics
task kafka-cluster-info      # Show cluster information
```

## Prerequisites

- **Snowflake Account**: Enterprise account with Openflow SPCS enabled
- **Kafka Cluster**: Access to Kafka (Confluent Cloud, AWS MSK, GCP Managed Kafka, or self-hosted)
- **Redpanda CLI (rpk)**: For Kafka operations ([install guide](https://docs.redpanda.com/current/get-started/rpk-install/))
  - üìñ See [RPK_CLI_README.md](RPK_CLI_README.md) for detailed setup with Confluent Cloud
- **Python 3.7+**: Optional, for the log generator script
- **Task Runner**: Optional, but recommended for simplified command execution

## Sample Data

**`sample-data/sample_logs.json`** (50 records):

- Base schema with 11 fields (timestamp, level, service, host, message, etc.)
- Web API requests, authentication, database operations, payments

**`sample-data/sample_logs_evolved.json`** (80 records):

- Evolved schema with 29 fields
- Includes additional fields: region, trace_id, auth_method, currency, payment_method, and more
- Contains system metrics (memory_percent, disk_usage_percent) for Cortex Search examples

**`sample-data/generate_logs.py`**:

- Generate custom log files: `python generate_logs.py --count 100 --output my_logs.json`
- Test Kafka connection: `python generate_logs.py --test-connection`
- Produce to Kafka: `python generate_logs.py --count 100`
- See `--help` for all options

## SQL Scripts

All SQL scripts are referenced in the quickstart guide:

- **`1.snowflake_setup.sql`** - Create role, database, warehouse, network rules, External Access Integration
- **`2.verify_ingestion.sql`** - Verify data ingestion and check record counts
- **`2a.verify_base_schema.sql`** - Validate base schema (11 fields)
- **`2b.verify_schema_evolution.sql`** - Verify evolved schema (29 fields) and automatic column detection
- **`3.analytics_queries.sql`** - Advanced analytics examples (log analysis, time-series, performance metrics)
- **`4.cortex_search.sql`** - Semantic search queries with Cortex Search
- **`5.cleanup.sql`** - Clean up all Snowflake resources

## Resources

**Quickstart & Documentation:**

- [Openflow Kafka Connector Quickstart](https://quickstarts.snowflake.com/guide/getting_started_with_openflow_kafka_connector/index.html) ‚≠ê
- [Openflow Documentation](https://docs.snowflake.com/en/user-guide/data-integration/openflow/about)
- [Kafka Connector Documentation](https://docs.snowflake.com/en/user-guide/data-integration/openflow/connectors/kafka/about)
- [rpk CLI Setup Guide](RPK_CLI_README.md)

**Related Quickstarts:**

- [Getting Started with Openflow SPCS](https://quickstarts.snowflake.com/guide/getting_started_with_openflow_spcs/index.html)
- [Getting Started with PostgreSQL CDC](https://quickstarts.snowflake.com/guide/getting_started_with_openflow_postgresql_cdc/index.html)
- [Getting Started with Unstructured Data Pipeline](https://quickstarts.snowflake.com/guide/getting_started_openflow_unstructured_data_pipeline/index.html)

## Support

- [Open an issue](https://github.com/Snowflake-Labs/sfquickstarts/issues) on GitHub
- Visit [Snowflake Community](https://community.snowflake.com/)

## License

Copyright (c) 2025 Snowflake Inc. All rights reserved.

Licensed under the Apache License, Version 2.0. See [LICENSE.txt](LICENSE.txt) for details.
